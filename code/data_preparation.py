# -*- coding: utf-8 -*-
"""data_preparation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yBuntHFy3ydNWi3wjubKjyykjhFse2L6
"""

# ================================================================
# CLIP Image-Text Retrieval Engine - Phase 1: Data Preparation
# Dataset: Flickr8k with Karpathy splits
# ================================================================

# 1. SETUP & ENVIRONMENT
print("ğŸš€ CLIP Project - Phase 1: Data Preparation")
print("=" * 50)

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import os
import json
import pandas as pd
import numpy as np
from PIL import Image
import zipfile
import urllib.request
import hashlib
from pathlib import Path
import shutil
from collections import defaultdict
import random

# Set random seeds for reproducibility
random.seed(42)
np.random.seed(42)

# Create project directory structure
project_root = '/content/drive/MyDrive/clip_image_text_retrieval'
os.makedirs(project_root, exist_ok=True)
os.chdir(project_root)

# Create all necessary subdirectories
dirs_to_create = [
    'data', 'data/raw', 'data/processed', 'data/images',
    'artifacts', 'artifacts/embeddings', 'artifacts/models', 'artifacts/indexes',
    'results', 'notebooks', 'reports'
]

for dir_path in dirs_to_create:
    os.makedirs(dir_path, exist_ok=True)

print(f"âœ… Project structure created at: {project_root}")
print(f"ğŸ“ Working directory: {os.getcwd()}")

# ================================================================
# 2. DATASET DOWNLOAD & EXTRACTION
# ================================================================

print("\nğŸ“¥ Downloading Flickr8k Dataset...")

# Install required packages for dataset loading
#!pip install datasets kaggle -q

# Method 1: Try Hugging Face first (cleanest option)
print("ğŸ¤— Attempting download from Hugging Face...")

try:
    from datasets import load_dataset

    # Load Flickr8k dataset from Hugging Face
    print("ğŸ“¥ Loading Flickr8k from HuggingFace (ariG23498/flickr8k)...")
    dataset = load_dataset("ariG23498/flickr8k")

    print("âœ… Successfully loaded from HuggingFace!")
    print(f"ğŸ“Š Dataset info: {dataset}")

    # Extract and save data
    os.makedirs("data/raw/Images", exist_ok=True)

    # Save images and create caption files
    all_captions = []
    train_images = []
    val_images = []
    test_images = []

    splits = ['train', 'test', 'validation'] if 'validation' in dataset else ['train', 'test']

    for split_name in splits:
        if split_name not in dataset:
            continue

        split_data = dataset[split_name]
        split_images = []

        print(f"Processing {split_name} split: {len(split_data)} entries...")

        for i, example in enumerate(split_data):
            image = example['image']
            caption = example['caption']

            # Generate image filename
            image_filename = f"{split_name}_{i:06d}.jpg"
            image_path = f"data/raw/Images/{image_filename}"

            # Save image
            image.save(image_path)

            # Store caption info
            all_captions.append(f"{image_filename}#0\t{caption}")
            split_images.append(image_filename)

            # Show progress
            if (i + 1) % 500 == 0:
                print(f"  Processed {i + 1}/{len(split_data)} images...")

        # Store split information
        if split_name == 'train':
            train_images = split_images
        elif split_name == 'test':
            test_images = split_images
        elif split_name == 'validation':
            val_images = split_images

    # Create validation split if not present
    if 'validation' not in dataset and len(test_images) >= 2000:
        # Split test into val and test
        print("Creating validation split from test data...")
        random.shuffle(test_images)
        val_images = test_images[:1000]
        test_images = test_images[1000:]

    # Save captions file
    with open("data/raw/Flickr8k.token.txt", 'w', encoding='utf-8') as f:
        f.write('\n'.join(all_captions))

    # Save split files
    with open("data/raw/Flickr_8k.trainImages.txt", 'w') as f:
        f.write('\n'.join(train_images))

    with open("data/raw/Flickr_8k.devImages.txt", 'w') as f:
        f.write('\n'.join(val_images))

    with open("data/raw/Flickr_8k.testImages.txt", 'w') as f:
        f.write('\n'.join(test_images))

    print("âœ… HuggingFace dataset successfully processed!")

except Exception as e:
    print(f"âš ï¸  HuggingFace method failed: {e}")
    print("ğŸ”„ Falling back to Kaggle download...")

    # Method 2: Kaggle fallback
    try:
        # Note: This requires Kaggle API key
        print("ğŸ“¥ Downloading from Kaggle (requires API key)...")
        print("ğŸ’¡ If this fails, please upload kaggle.json to Colab or use manual download")

        # Try to download from Kaggle
        #!kaggle datasets download -d adityajn105/flickr8k -p data/raw/ --unzip

        # Check if files were downloaded
        if os.path.exists("data/raw/captions.txt") and os.path.exists("data/raw/Images"):
            print("âœ… Kaggle download successful!")

            # Convert Kaggle format to standard format
            captions_df = pd.read_csv("data/raw/captions.txt")

            # Create standard caption file
            with open("data/raw/Flickr8k.token.txt", 'w', encoding='utf-8') as f:
                for _, row in captions_df.iterrows():
                    f.write(f"{row['image']}#0\t{row['caption']}\n")

            # Create standard splits (if not present)
            all_images = list(captions_df['image'].unique())
            random.shuffle(all_images)

            n_total = len(all_images)
            n_train = int(0.7 * n_total)
            n_val = int(0.15 * n_total)

            train_images = all_images[:n_train]
            val_images = all_images[n_train:n_train + n_val]
            test_images = all_images[n_train + n_val:]

            # Save split files
            with open("data/raw/Flickr_8k.trainImages.txt", 'w') as f:
                f.write('\n'.join(train_images))

            with open("data/raw/Flickr_8k.devImages.txt", 'w') as f:
                f.write('\n'.join(val_images))

            with open("data/raw/Flickr_8k.testImages.txt", 'w') as f:
                f.write('\n'.join(test_images))

        else:
            raise FileNotFoundError("Kaggle download failed or files not found")

    except Exception as e2:
        print(f"âŒ Kaggle method also failed: {e2}")
        print("\nğŸ”§ MANUAL DOWNLOAD INSTRUCTIONS:")
        print("=" * 40)
        print("1. Go to: https://www.kaggle.com/datasets/adityajn105/flickr8k")
        print("2. Download the dataset manually")
        print("3. Upload to Colab and extract to data/raw/")
        print("4. Re-run this cell")
        print("\nAlternatively:")
        print("1. Upload your kaggle.json file to Colab")
        print("2. Run: !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json")
        print("3. Re-run this cell")
        raise

# ================================================================
# SECTION 3 FIX: PROCESS HUGGINGFACE DATASET CORRECTLY
# Group every 5 rows (same image, different captions)
# ================================================================

print("ğŸ”§ SECTION 3 FIX: PROCESSING HUGGINGFACE DATASET")
print("=" * 50)

# Read the current caption file
captions_file = "data/raw/Flickr8k.token.txt"

print(f"ğŸ“– Reading captions from: {captions_file}")

# Read all lines
with open(captions_file, 'r', encoding='utf-8') as f:
    all_lines = [line.strip() for line in f if line.strip()]

print(f"ğŸ“Š Total caption lines: {len(all_lines)}")

# Process every 5 lines as one image with 5 captions
captions_dict = defaultdict(list)
unique_images = []

for i in range(0, len(all_lines), 5):
    # Get the next 5 lines (or remaining lines if less than 5)
    batch = all_lines[i:i+5]

    if not batch:
        break

    # Get the image name from the first line of the batch
    first_line = batch[0]
    if '\t' in first_line:
        image_caption_id, caption = first_line.split('\t', 1)
        base_image_name = image_caption_id.split('#')[0]

        # Create a proper image name
        # Convert train_000000.jpg to flickr8k_000000.jpg
        img_num = i // 5  # Unique image number
        proper_image_name = f"flickr8k_{img_num:06d}.jpg"

        unique_images.append(proper_image_name)

        # Collect all captions for this image
        for line in batch:
            if '\t' in line:
                _, caption = line.split('\t', 1)
                caption = caption.strip().lower()
                captions_dict[proper_image_name].append(caption)

    # Show progress
    if (i // 5 + 1) % 1000 == 0:
        print(f"  Processed {i//5 + 1} unique images...")

print(f"âœ… Processed dataset:")
print(f"  Unique images: {len(unique_images)}")
print(f"  Total captions: {sum(len(caps) for caps in captions_dict.values())}")

# Check captions per image
captions_per_image = [len(caps) for caps in captions_dict.values()]
print(f"  Captions per image: mean={np.mean(captions_per_image):.1f}, min={min(captions_per_image)}, max={max(captions_per_image)}")

# Show sample
print(f"\nğŸ“‹ Sample processed data:")
sample_image = unique_images[0]
print(f"Image: {sample_image}")
for i, caption in enumerate(captions_dict[sample_image][:3]):
    print(f"  Caption {i+1}: {caption}")

print(f"\nâœ… Section 3 Fix Complete! Run Section 4 next.")

# ================================================================
# SECTION 4 FIX: CREATE PROPER SPLITS BY UNIQUE IMAGES
# ================================================================

print("ğŸ¯ SECTION 4 FIX: CREATING SPLITS BY UNIQUE IMAGES")
print("=" * 50)

# Shuffle unique images for random splits
random.seed(42)
shuffled_images = unique_images.copy()
random.shuffle(shuffled_images)

# Create splits
n_total = len(shuffled_images)
n_train = int(0.7 * n_total)
n_val = int(0.15 * n_total)

train_images = shuffled_images[:n_train]
val_images = shuffled_images[n_train:n_train + n_val]
test_images = shuffled_images[n_train + n_val:]

print(f"ğŸ“Š Split by unique images:")
print(f"  Train: {len(train_images)} images")
print(f"  Val:   {len(val_images)} images")
print(f"  Test:  {len(test_images)} images")

# Count total captions per split
train_captions = sum(len(captions_dict[img]) for img in train_images)
val_captions = sum(len(captions_dict[img]) for img in val_images)
test_captions = sum(len(captions_dict[img]) for img in test_images)

print(f"ğŸ“Š Total captions per split:")
print(f"  Train: {train_captions} captions")
print(f"  Val:   {val_captions} captions")
print(f"  Test:  {test_captions} captions")

# Save split files (for compatibility with original code structure)
with open("data/raw/Flickr_8k.trainImages.txt", 'w') as f:
    f.write('\n'.join(train_images))

with open("data/raw/Flickr_8k.devImages.txt", 'w') as f:
    f.write('\n'.join(val_images))

with open("data/raw/Flickr_8k.testImages.txt", 'w') as f:
    f.write('\n'.join(test_images))

print(f"âœ… Split files updated with proper image names")
print(f"âœ… Section 4 Fix Complete! Run Section 5 next.")

# THIS CODE SECTION IS A FAILED VERSION. THE CORRECT WORKING SECTION 5 IS BELOW THE DEBUG CELLS

# ================================================================
# SECTION 5 FIX: ORGANIZE IMAGES WITH PROPER NAMES
# ================================================================

# print("ğŸ–¼ï¸ SECTION 5 FIX: ORGANIZING IMAGES WITH PROPER NAMES")
# print("=" * 50)

# # Create mapping from old to new image names
# source_images_dir = "data/raw/Images"
# target_dir = "data/images"
# os.makedirs(target_dir, exist_ok=True)

# print(f"ğŸ“ Source: {source_images_dir}")
# print(f"ğŸ“ Target: {target_dir}")

# # Check source directory
# if not os.path.exists(source_images_dir):
#     print(f"âŒ Source directory not found: {source_images_dir}")
#     print("Available directories in data/raw/:")
#     for item in os.listdir("data/raw/"):
#         if os.path.isdir(os.path.join("data/raw/", item)):
#             print(f"  {item}/")
# else:
#     source_files = [f for f in os.listdir(source_images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]
#     print(f"ğŸ“Š Found {len(source_files)} source images")

# # Copy and rename images
# valid_images = {'train': [], 'val': [], 'test': []}
# copied_count = 0

# print(f"ğŸ“‹ Copying images with new names...")

# for split_name, image_list in [('train', train_images), ('val', val_images), ('test', test_images)]:
#     print(f"\nProcessing {split_name} split ({len(image_list)} images)...")

#     for new_image_name in image_list:
#         # Calculate original image index
#         img_index = int(new_image_name.split('_')[1].split('.')[0])

#         # Original image name pattern (every 5th image starting from 0)
#         original_index = img_index * 5
#         old_image_name = f"train_{original_index:06d}.jpg"

#         source_path = os.path.join(source_images_dir, old_image_name)
#         target_path = os.path.join(target_dir, new_image_name)

#         if os.path.exists(source_path):
#             try:
#                 import shutil
#                 shutil.copy2(source_path, target_path)

#                 # Validate image can be opened
#                 with Image.open(target_path) as img:
#                     if img.size[0] > 0 and img.size[1] > 0:
#                         valid_images[split_name].append(new_image_name)
#                         copied_count += 1
#                     else:
#                         print(f"âš ï¸ Invalid image dimensions: {new_image_name}")

#             except Exception as e:
#                 print(f"âš ï¸ Failed to copy {old_image_name} -> {new_image_name}: {e}")
#         else:
#             print(f"âš ï¸ Source image not found: {source_path}")

#         # Show progress every 500 images
#         if len(valid_images[split_name]) % 500 == 0 and len(valid_images[split_name]) > 0:
#             print(f"  Copied {len(valid_images[split_name])} images...")

#     print(f"  âœ… {split_name}: {len(valid_images[split_name])} valid images")

# print(f"\nâœ… Image organization complete!")
# print(f"ğŸ“Š Successfully copied {copied_count} total images")
# print(f"ğŸ“Š Final counts:")
# for split_name in ['train', 'val', 'test']:
#     print(f"  {split_name}: {len(valid_images[split_name])} images")

# print(f"\nâœ… Section 5 Fix Complete! Run Section 6 next.")

print("ğŸ” DEBUGGING STEP 1: Basic System Check")
print("=" * 40)

import time
start_time = time.time()

# Check if we can even access the directories
try:
    target_files = os.listdir("data/images")
    print(f"âœ… Target directory accessible: {len(target_files)} files")
except Exception as e:
    print(f"âŒ Target directory issue: {e}")

try:
    source_files = os.listdir("data/raw/Images")
    print(f"âœ… Source directory accessible: {len(source_files)} files")
except Exception as e:
    print(f"âŒ Source directory issue: {e}")

elapsed = time.time() - start_time
print(f"â±ï¸ Basic checks took: {elapsed:.2f} seconds")

# If this is fast, the issue is elsewhere
# If this is slow, we have a file system problem

print("ğŸ” DEBUGGING STEP 2: Find Exact Failure Point")
print("=" * 40)

# Find what we actually have
copied_files = [f for f in os.listdir("data/images") if f.startswith("flickr8k_")]
print(f"ğŸ“Š Flickr8k files copied: {len(copied_files)}")

# Get the image numbers we successfully copied
copied_numbers = []
for f in copied_files:
    try:
        num = int(f.split('_')[1].split('.')[0])
        copied_numbers.append(num)
    except:
        pass

if copied_numbers:
    copied_numbers.sort()
    max_copied = max(copied_numbers)
    print(f"ğŸ“Š Highest number copied: {max_copied}")
    print(f"ğŸ“Š Range: {min(copied_numbers)} to {max_copied}")

    # Check for gaps in sequence
    expected = set(range(min(copied_numbers), max_copied + 1))
    actual = set(copied_numbers)
    missing = expected - actual

    if missing:
        print(f"âš ï¸ Missing numbers: {sorted(list(missing))[:10]}...")  # Show first 10
    else:
        print("âœ… No gaps in sequence")

    # The next image to copy (where it failed)
    next_to_copy = max_copied + 1
    print(f"\nğŸ¯ Next image to copy: flickr8k_{next_to_copy:06d}.jpg")

    # Check if this image should exist in our train set
    if next_to_copy < len(train_images):
        print(f"âœ… This image should be in train set")

        # Calculate source file
        source_idx = next_to_copy * 5
        source_file = f"train_{source_idx:06d}.jpg"
        source_path = f"data/raw/Images/{source_file}"

        print(f"ğŸ“‚ Looking for source: {source_file}")
        print(f"ğŸ“‚ Path exists: {os.path.exists(source_path)}")

        if os.path.exists(source_path):
            size = os.path.getsize(source_path)
            print(f"ğŸ“‚ File size: {size:,} bytes")

            # Try opening it
            try:
                from PIL import Image
                with Image.open(source_path) as img:
                    print(f"âœ… Image opens fine: {img.size} {img.mode}")
            except Exception as e:
                print(f"âŒ Cannot open image: {e}")
        else:
            print(f"âŒ Source file missing!")
    else:
        print(f"âš ï¸ Beyond train set - should be in val/test")

print("ğŸ” DEBUGGING STEP 3: Check Image Mapping Logic")
print("=" * 40)

# Check what source images we actually have
source_files = os.listdir("data/raw/Images")
source_numbers = []

for f in source_files:
    if f.startswith("train_") and f.endswith(".jpg"):
        try:
            num = int(f.split('_')[1].split('.')[0])
            source_numbers.append(num)
        except:
            pass

source_numbers.sort()
print(f"ğŸ“Š Source images range: {min(source_numbers)} to {max(source_numbers)}")
print(f"ğŸ“Š Total source images: {len(source_numbers)}")

# Check if they're sequential every 5
expected_sequence = list(range(0, max(source_numbers) + 1, 5))
actual_set = set(source_numbers)
expected_set = set(expected_sequence)

missing_expected = expected_set - actual_set
print(f"ğŸ“Š Missing from expected sequence: {len(missing_expected)}")
if missing_expected:
    print(f"   First few missing: {sorted(list(missing_expected))[:10]}")

# Check the pattern
print(f"\nğŸ” First 20 source images: {source_numbers[:20]}")
print(f"ğŸ” Pattern check - every 5th: {source_numbers[::5][:10]}")

print("ğŸ” DEBUGGING STEP 4: Check Failed Copies")
print("=" * 40)

# Let's manually check some of the "missing" numbers
missing_samples = [2, 3, 4, 5, 7, 8, 9]  # From our earlier output

for img_num in missing_samples:
    print(f"\nğŸ” Checking missing image {img_num}:")

    # Calculate source
    source_idx = img_num * 5
    source_file = f"train_{source_idx:06d}.jpg"
    source_path = f"data/raw/Images/{source_file}"

    # Calculate target
    target_file = f"flickr8k_{img_num:06d}.jpg"
    target_path = f"data/images/{target_file}"

    print(f"  Source: {source_file} (exists: {os.path.exists(source_path)})")
    print(f"  Target: {target_file} (exists: {os.path.exists(target_path)})")

    if os.path.exists(source_path) and not os.path.exists(target_path):
        # Try to copy this one manually
        try:
            import shutil
            shutil.copy2(source_path, target_path)
            print(f"  âœ… Manual copy successful!")
        except Exception as e:
            print(f"  âŒ Manual copy failed: {e}")
            break  # Stop at first error
    elif os.path.exists(target_path):
        print(f"  â„¹ï¸ Target actually exists - counting error?")

# Quick recount
actual_copied = len([f for f in os.listdir("data/images") if f.startswith("flickr8k_")])
print(f"\nğŸ“Š Actual files after check: {actual_copied}")

print("ğŸ”§ SECTION 5 FIX v2: ROBUST IMAGE COPYING")
print("=" * 50)

import shutil
import time
from PIL import Image

def robust_copy_images():
    """Copy images with proper error handling and progress"""

    # Count what we have so far
    existing_files = [f for f in os.listdir("data/images") if f.startswith("flickr8k_")]
    existing_numbers = set()

    for f in existing_files:
        try:
            num = int(f.split('_')[1].split('.')[0])
            existing_numbers.add(num)
        except:
            pass

    print(f"ğŸ“Š Starting with {len(existing_numbers)} existing files")

    # Process each split
    for split_name, image_list in [('train', train_images), ('val', val_images), ('test', test_images)]:
        print(f"\nğŸ“‹ Processing {split_name} split ({len(image_list)} images)...")

        successful = 0
        failed = 0
        skipped = 0

        for i, new_image_name in enumerate(image_list):
            # Extract image number
            img_num = int(new_image_name.split('_')[1].split('.')[0])

            # Skip if already exists
            if img_num in existing_numbers:
                skipped += 1
                continue

            # Calculate source path
            source_idx = img_num * 5
            source_file = f"train_{source_idx:06d}.jpg"
            source_path = f"data/raw/Images/{source_file}"
            target_path = f"data/images/{new_image_name}"

            # Copy with error handling
            try:
                # Add small delay to prevent overwhelming Google Drive
                if i % 50 == 0 and i > 0:
                    time.sleep(0.5)  # Brief pause every 50 files

                shutil.copy2(source_path, target_path)

                # Validate the copy
                with Image.open(target_path) as img:
                    if img.size[0] > 0 and img.size[1] > 0:
                        successful += 1
                        existing_numbers.add(img_num)
                    else:
                        failed += 1
                        os.remove(target_path)  # Remove invalid file

            except Exception as e:
                failed += 1
                print(f"  âš ï¸ Failed to copy {new_image_name}: {e}")

                # If too many failures, stop and investigate
                if failed > 10:
                    print(f"  ğŸ›‘ Too many failures, stopping to investigate")
                    break

            # Progress updates
            if (successful + failed + skipped) % 500 == 0:
                print(f"    Progress: {successful} success, {failed} failed, {skipped} skipped")

        print(f"  âœ… {split_name}: {successful} copied, {failed} failed, {skipped} skipped")

        # Stop if too many failures
        if failed > 10:
            break

    return existing_numbers

# Run the robust copy
final_copied = robust_copy_images()
print(f"\nğŸ‰ Final result: {len(final_copied)} images ready")

print("ğŸ“„ SECTION 6 FIX v2: CREATING JSONL FILES (CORRECTED)")
print("=" * 50)

# Rebuild valid_images from what we actually have
print("ğŸ”§ Rebuilding valid_images from copied files...")

# Get all successfully copied images
copied_files = [f for f in os.listdir("data/images") if f.startswith("flickr8k_")]
copied_image_names = set(copied_files)

print(f"ğŸ“Š Found {len(copied_image_names)} copied images")

# Rebuild valid_images by checking which images from each split actually exist
valid_images = {'train': [], 'val': [], 'test': []}

for split_name, image_list in [('train', train_images), ('val', val_images), ('test', test_images)]:
    for img_name in image_list:
        if img_name in copied_image_names:
            valid_images[split_name].append(img_name)

    print(f"ğŸ“Š {split_name}: {len(valid_images[split_name])} valid images")

# Now create JSONL files with corrected valid_images
def create_jsonl_fixed(image_list, split_name, output_file):
    """Create JSONL file with proper format"""
    entries = []

    for img_name in image_list:
        if img_name not in captions_dict:
            print(f"âš ï¸ No captions found for {img_name}")
            continue

        # Create entry for each caption
        for i, caption in enumerate(captions_dict[img_name]):
            entry = {
                'image_path': f'data/images/{img_name}',
                'caption': caption,
                'image_id': img_name.split('.')[0],  # Remove .jpg extension
                'caption_id': f"{img_name.split('.')[0]}_{i}",
                'split': split_name
            }
            entries.append(entry)

    # Save JSONL
    with open(output_file, 'w', encoding='utf-8') as f:
        for entry in entries:
            f.write(json.dumps(entry) + '\n')

    print(f"  âœ… {split_name}: {len(entries)} entries â†’ {output_file}")
    return entries

# Create JSONL files for each split
print("\nğŸ“ Creating JSONL files...")

train_data = create_jsonl_fixed(valid_images['train'], 'train', 'data/train.jsonl')
val_data = create_jsonl_fixed(valid_images['val'], 'val', 'data/val.jsonl')
test_data = create_jsonl_fixed(valid_images['test'], 'test', 'data/test.jsonl')

print(f"\nğŸ“Š JSONL Files Created:")
print(f"  train.jsonl: {len(train_data)} entries")
print(f"  val.jsonl: {len(val_data)} entries")
print(f"  test.jsonl: {len(test_data)} entries")

# Verify average captions per image
print(f"\nğŸ“Š Verification - Average captions per image:")
for split_name, image_list in [('train', valid_images['train']), ('val', valid_images['val']), ('test', valid_images['test'])]:
    if image_list:
        total_captions = sum(len(captions_dict[img]) for img in image_list)
        avg_captions = total_captions / len(image_list)
        print(f"  {split_name}: {avg_captions:.1f} captions/image")

print(f"\nâœ… Section 6 Fix v2 Complete! Run Section 7 next.")

# ================================================================
# SECTION 7 FIX: FINAL VALIDATION & DOCUMENTATION
# ================================================================

print("ğŸ§ª SECTION 7 FIX: FINAL VALIDATION & DOCUMENTATION")
print("=" * 50)

# ================================================================
# FINAL VALIDATION
# ================================================================

print("ğŸ” Final Validation:")

# Check all files exist
required_files = ['data/train.jsonl', 'data/val.jsonl', 'data/test.jsonl']
for file_path in required_files:
    if os.path.exists(file_path):
        size_mb = os.path.getsize(file_path) / (1024 * 1024)
        print(f"âœ… {file_path} ({size_mb:.2f} MB)")
    else:
        print(f"âŒ Missing: {file_path}")

# Test data loading
print(f"\nğŸ§ª Testing data loading:")
try:
    # Test JSONL format
    with open('data/train.jsonl', 'r') as f:
        sample_entry = json.loads(f.readline())

    print("âœ… JSONL format valid")
    print(f"ğŸ“‹ Sample entry keys: {list(sample_entry.keys())}")
    print(f"ğŸ“‹ Sample entry:")
    for key, value in sample_entry.items():
        if key == 'caption':
            print(f"  {key}: {value[:50]}...")  # Truncate long captions
        else:
            print(f"  {key}: {value}")

    # Test image loading
    sample_image_path = sample_entry['image_path']
    if os.path.exists(sample_image_path):
        with Image.open(sample_image_path) as img:
            print(f"âœ… Sample image loads: {img.size} {img.mode}")
    else:
        print(f"âŒ Sample image missing: {sample_image_path}")

except Exception as e:
    print(f"âŒ Data loading test failed: {e}")

# ================================================================
# CREATE DOCUMENTATION
# ================================================================

print(f"\nğŸ“š Creating documentation...")

# Calculate file checksums for reproducibility
def calculate_checksum(file_path):
    """Calculate MD5 checksum of file"""
    import hashlib
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

# Create README
readme_content = f"""# Flickr8k Dataset - CLIP Project (Fixed)

## Dataset Information
- **Source**: HuggingFace ariG23498/flickr8k (processed correctly)
- **Total Unique Images**: {len(unique_images)}
- **Total Captions**: {len(train_data) + len(val_data) + len(test_data)}

## Processing Applied
- **Fixed grouping**: Every 5 captions grouped to 1 unique image
- **Proper splits**: Split by unique images (not by captions)
- **Image renaming**: train_000000.jpg â†’ flickr8k_000000.jpg pattern

## Splits
- **Train**: {len(valid_images['train'])} images, {len(train_data)} captions
- **Validation**: {len(valid_images['val'])} images, {len(val_data)} captions
- **Test**: {len(valid_images['test'])} images, {len(test_data)} captions

## File Checksums (for reproducibility)
- `train.jsonl`: {calculate_checksum('data/train.jsonl')}
- `val.jsonl`: {calculate_checksum('data/val.jsonl')}
- `test.jsonl`: {calculate_checksum('data/test.jsonl')}

## Data Format
Each JSONL file contains entries with:
- `image_path`: Relative path to image file
- `caption`: Preprocessed caption text (lowercase, normalized)
- `image_id`: Unique image identifier
- `caption_id`: Unique caption identifier
- `split`: Dataset split name

## Preprocessing Applied
- Captions converted to lowercase
- Whitespace normalized
- UTF-8 encoding ensured
- Images validated for corruption
- Images renamed for clarity (flickr8k_XXXXXX.jpg)

## Usage
```python
import json

# Load training data
with open('data/train.jsonl', 'r') as f:
    train_data = [json.loads(line) for line in f]
```

Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

with open('data/README.md', 'w', encoding='utf-8') as f:
    f.write(readme_content)

print("âœ… Dataset documentation created: data/README.md")

# ================================================================
# FINAL SUMMARY
# ================================================================

print(f"\n" + "="*60)
print("ğŸ‰ DATASET PREPARATION COMPLETE!")
print("="*60)

print(f"ğŸ“Š Final Dataset Statistics:")
print(f"  Unique Images: {len(unique_images)}")
print(f"  Train: {len(valid_images['train'])} images, {len(train_data)} captions")
print(f"  Val:   {len(valid_images['val'])} images, {len(val_data)} captions")
print(f"  Test:  {len(valid_images['test'])} images, {len(test_data)} captions")

avg_captions = (len(train_data) + len(val_data) + len(test_data)) / len(unique_images)
print(f"  Average captions per image: {avg_captions:.1f}")

print(f"\nğŸ“ Files Created:")
print(f"  â€¢ data/train.jsonl ({len(train_data)} entries)")
print(f"  â€¢ data/val.jsonl ({len(val_data)} entries)")
print(f"  â€¢ data/test.jsonl ({len(test_data)} entries)")
print(f"  â€¢ data/images/ ({sum(len(v) for v in valid_images.values())} images)")
print(f"  â€¢ data/README.md (documentation)")

print(f"\nğŸš€ Ready for Phase 2: Zero-shot Baseline!")
print("ğŸ’¡ Next: Create zero-shot encoding notebook")

# Save project state for next phase
project_state = {
    'phase_completed': 'data_preparation_fixed',
    'dataset': 'flickr8k_grouped_corrected',
    'total_unique_images': len(unique_images),
    'total_captions': len(train_data) + len(val_data) + len(test_data),
    'splits': {
        'train': {'images': len(valid_images['train']), 'captions': len(train_data)},
        'val': {'images': len(valid_images['val']), 'captions': len(val_data)},
        'test': {'images': len(valid_images['test']), 'captions': len(test_data)}
    },
    'project_root': project_root,
    'next_phase': 'zero_shot_baseline'
}

with open('artifacts/project_state.json', 'w') as f:
    json.dump(project_state, f, indent=2)

print("ğŸ’¾ Project state saved to artifacts/project_state.json")
print(f"\nâœ… Section 7 Fix Complete! Data preparation finished!")
