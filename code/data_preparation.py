# -*- coding: utf-8 -*-
"""data_preparation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yBuntHFy3ydNWi3wjubKjyykjhFse2L6
"""

# ================================================================
# CLIP Image-Text Retrieval Engine - Phase 1: Data Preparation
# Dataset: Flickr8k with Karpathy splits
# ================================================================

# 1. SETUP & ENVIRONMENT
print("üöÄ CLIP Project - Phase 1: Data Preparation")
print("=" * 50)

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import os
import json
import pandas as pd
import numpy as np
from PIL import Image
import zipfile
import urllib.request
import hashlib
from pathlib import Path
import shutil
from collections import defaultdict
import random

# Set random seeds for reproducibility
random.seed(42)
np.random.seed(42)

# Create project directory structure
project_root = '/content/drive/MyDrive/clip_image_text_retrieval'
os.makedirs(project_root, exist_ok=True)
os.chdir(project_root)

# Create all necessary subdirectories
dirs_to_create = [
    'data', 'data/raw', 'data/processed', 'data/images',
    'artifacts', 'artifacts/embeddings', 'artifacts/models', 'artifacts/indexes',
    'results', 'notebooks', 'reports'
]

for dir_path in dirs_to_create:
    os.makedirs(dir_path, exist_ok=True)

print(f"‚úÖ Project structure created at: {project_root}")
print(f"üìÅ Working directory: {os.getcwd()}")

# ================================================================
# 2. DATASET DOWNLOAD & EXTRACTION
# ================================================================

print("\nüì• Downloading Flickr8k Dataset...")

# Install required packages for dataset loading
#!pip install datasets kaggle -q

# Method 1: Try Hugging Face first (cleanest option)
print("ü§ó Attempting download from Hugging Face...")

try:
    from datasets import load_dataset

    # Load Flickr8k dataset from Hugging Face
    print("üì• Loading Flickr8k from HuggingFace (ariG23498/flickr8k)...")
    dataset = load_dataset("ariG23498/flickr8k")

    print("‚úÖ Successfully loaded from HuggingFace!")
    print(f"üìä Dataset info: {dataset}")

    # Extract and save data
    os.makedirs("data/raw/Images", exist_ok=True)

    # Save images and create caption files
    all_captions = []
    train_images = []
    val_images = []
    test_images = []

    splits = ['train', 'test', 'validation'] if 'validation' in dataset else ['train', 'test']

    for split_name in splits:
        if split_name not in dataset:
            continue

        split_data = dataset[split_name]
        split_images = []

        print(f"Processing {split_name} split: {len(split_data)} entries...")

        for i, example in enumerate(split_data):
            image = example['image']
            caption = example['caption']

            # Generate image filename
            image_filename = f"{split_name}_{i:06d}.jpg"
            image_path = f"data/raw/Images/{image_filename}"

            # Save image
            image.save(image_path)

            # Store caption info
            all_captions.append(f"{image_filename}#0\t{caption}")
            split_images.append(image_filename)

            # Show progress
            if (i + 1) % 500 == 0:
                print(f"  Processed {i + 1}/{len(split_data)} images...")

        # Store split information
        if split_name == 'train':
            train_images = split_images
        elif split_name == 'test':
            test_images = split_images
        elif split_name == 'validation':
            val_images = split_images

    # Create validation split if not present
    if 'validation' not in dataset and len(test_images) >= 2000:
        # Split test into val and test
        print("Creating validation split from test data...")
        random.shuffle(test_images)
        val_images = test_images[:1000]
        test_images = test_images[1000:]

    # Save captions file
    with open("data/raw/Flickr8k.token.txt", 'w', encoding='utf-8') as f:
        f.write('\n'.join(all_captions))

    # Save split files
    with open("data/raw/Flickr_8k.trainImages.txt", 'w') as f:
        f.write('\n'.join(train_images))

    with open("data/raw/Flickr_8k.devImages.txt", 'w') as f:
        f.write('\n'.join(val_images))

    with open("data/raw/Flickr_8k.testImages.txt", 'w') as f:
        f.write('\n'.join(test_images))

    print("‚úÖ HuggingFace dataset successfully processed!")

except Exception as e:
    print(f"‚ö†Ô∏è  HuggingFace method failed: {e}")
    print("üîÑ Falling back to Kaggle download...")

    # Method 2: Kaggle fallback
    try:
        # Note: This requires Kaggle API key
        print("üì• Downloading from Kaggle (requires API key)...")
        print("üí° If this fails, please upload kaggle.json to Colab or use manual download")

        # Try to download from Kaggle
        #!kaggle datasets download -d adityajn105/flickr8k -p data/raw/ --unzip

        # Check if files were downloaded
        if os.path.exists("data/raw/captions.txt") and os.path.exists("data/raw/Images"):
            print("‚úÖ Kaggle download successful!")

            # Convert Kaggle format to standard format
            captions_df = pd.read_csv("data/raw/captions.txt")

            # Create standard caption file
            with open("data/raw/Flickr8k.token.txt", 'w', encoding='utf-8') as f:
                for _, row in captions_df.iterrows():
                    f.write(f"{row['image']}#0\t{row['caption']}\n")

            # Create standard splits (if not present)
            all_images = list(captions_df['image'].unique())
            random.shuffle(all_images)

            n_total = len(all_images)
            n_train = int(0.7 * n_total)
            n_val = int(0.15 * n_total)

            train_images = all_images[:n_train]
            val_images = all_images[n_train:n_train + n_val]
            test_images = all_images[n_train + n_val:]

            # Save split files
            with open("data/raw/Flickr_8k.trainImages.txt", 'w') as f:
                f.write('\n'.join(train_images))

            with open("data/raw/Flickr_8k.devImages.txt", 'w') as f:
                f.write('\n'.join(val_images))

            with open("data/raw/Flickr_8k.testImages.txt", 'w') as f:
                f.write('\n'.join(test_images))

        else:
            raise FileNotFoundError("Kaggle download failed or files not found")

    except Exception as e2:
        print(f"‚ùå Kaggle method also failed: {e2}")
        print("\nüîß MANUAL DOWNLOAD INSTRUCTIONS:")
        print("=" * 40)
        print("1. Go to: https://www.kaggle.com/datasets/adityajn105/flickr8k")
        print("2. Download the dataset manually")
        print("3. Upload to Colab and extract to data/raw/")
        print("4. Re-run this cell")
        print("\nAlternatively:")
        print("1. Upload your kaggle.json file to Colab")
        print("2. Run: !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json")
        print("3. Re-run this cell")
        raise

# ================================================================
# SECTION 3 FIX: PROCESS HUGGINGFACE DATASET CORRECTLY
# Group every 5 rows (same image, different captions)
# ================================================================

print("üîß SECTION 3 FIX: PROCESSING HUGGINGFACE DATASET")
print("=" * 50)

# Read the current caption file
captions_file = "data/raw/Flickr8k.token.txt"

print(f"üìñ Reading captions from: {captions_file}")

# Read all lines
with open(captions_file, 'r', encoding='utf-8') as f:
    all_lines = [line.strip() for line in f if line.strip()]

print(f"üìä Total caption lines: {len(all_lines)}")

# Process every 5 lines as one image with 5 captions
captions_dict = defaultdict(list)
unique_images = []

for i in range(0, len(all_lines), 5):
    # Get the next 5 lines (or remaining lines if less than 5)
    batch = all_lines[i:i+5]

    if not batch:
        break

    # Get the image name from the first line of the batch
    first_line = batch[0]
    if '\t' in first_line:
        image_caption_id, caption = first_line.split('\t', 1)
        base_image_name = image_caption_id.split('#')[0]

        # Create a proper image name
        # Convert train_000000.jpg to flickr8k_000000.jpg
        img_num = i // 5  # Unique image number
        proper_image_name = f"flickr8k_{img_num:06d}.jpg"

        unique_images.append(proper_image_name)

        # Collect all captions for this image
        for line in batch:
            if '\t' in line:
                _, caption = line.split('\t', 1)
                caption = caption.strip().lower()
                captions_dict[proper_image_name].append(caption)

    # Show progress
    if (i // 5 + 1) % 1000 == 0:
        print(f"  Processed {i//5 + 1} unique images...")

print(f"‚úÖ Processed dataset:")
print(f"  Unique images: {len(unique_images)}")
print(f"  Total captions: {sum(len(caps) for caps in captions_dict.values())}")

# Check captions per image
captions_per_image = [len(caps) for caps in captions_dict.values()]
print(f"  Captions per image: mean={np.mean(captions_per_image):.1f}, min={min(captions_per_image)}, max={max(captions_per_image)}")

# Show sample
print(f"\nüìã Sample processed data:")
sample_image = unique_images[0]
print(f"Image: {sample_image}")
for i, caption in enumerate(captions_dict[sample_image][:3]):
    print(f"  Caption {i+1}: {caption}")

print(f"\n‚úÖ Section 3 Fix Complete! Run Section 4 next.")

# ================================================================
# SECTION 4 FIX: CREATE PROPER SPLITS BY UNIQUE IMAGES
# ================================================================

print("üéØ SECTION 4 FIX: CREATING SPLITS BY UNIQUE IMAGES")
print("=" * 50)

# Shuffle unique images for random splits
random.seed(42)
shuffled_images = unique_images.copy()
random.shuffle(shuffled_images)

# Create splits
n_total = len(shuffled_images)
n_train = int(0.7 * n_total)
n_val = int(0.15 * n_total)

train_images = shuffled_images[:n_train]
val_images = shuffled_images[n_train:n_train + n_val]
test_images = shuffled_images[n_train + n_val:]

print(f"üìä Split by unique images:")
print(f"  Train: {len(train_images)} images")
print(f"  Val:   {len(val_images)} images")
print(f"  Test:  {len(test_images)} images")

# Count total captions per split
train_captions = sum(len(captions_dict[img]) for img in train_images)
val_captions = sum(len(captions_dict[img]) for img in val_images)
test_captions = sum(len(captions_dict[img]) for img in test_images)

print(f"üìä Total captions per split:")
print(f"  Train: {train_captions} captions")
print(f"  Val:   {val_captions} captions")
print(f"  Test:  {test_captions} captions")

# Save split files (for compatibility with original code structure)
with open("data/raw/Flickr_8k.trainImages.txt", 'w') as f:
    f.write('\n'.join(train_images))

with open("data/raw/Flickr_8k.devImages.txt", 'w') as f:
    f.write('\n'.join(val_images))

with open("data/raw/Flickr_8k.testImages.txt", 'w') as f:
    f.write('\n'.join(test_images))

print(f"‚úÖ Split files updated with proper image names")
print(f"‚úÖ Section 4 Fix Complete! Run Section 5 next.")

# THIS CODE SECTION IS A FAILED VERSION. THE CORRECT WORKING SECTION 5 IS BELOW THE DEBUG CELLS

# ================================================================
# SECTION 5 FIX: ORGANIZE IMAGES WITH PROPER NAMES
# ================================================================

# print("üñºÔ∏è SECTION 5 FIX: ORGANIZING IMAGES WITH PROPER NAMES")
# print("=" * 50)

# # Create mapping from old to new image names
# source_images_dir = "data/raw/Images"
# target_dir = "data/images"
# os.makedirs(target_dir, exist_ok=True)

# print(f"üìÅ Source: {source_images_dir}")
# print(f"üìÅ Target: {target_dir}")

# # Check source directory
# if not os.path.exists(source_images_dir):
#     print(f"‚ùå Source directory not found: {source_images_dir}")
#     print("Available directories in data/raw/:")
#     for item in os.listdir("data/raw/"):
#         if os.path.isdir(os.path.join("data/raw/", item)):
#             print(f"  {item}/")
# else:
#     source_files = [f for f in os.listdir(source_images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]
#     print(f"üìä Found {len(source_files)} source images")

# # Copy and rename images
# valid_images = {'train': [], 'val': [], 'test': []}
# copied_count = 0

# print(f"üìã Copying images with new names...")

# for split_name, image_list in [('train', train_images), ('val', val_images), ('test', test_images)]:
#     print(f"\nProcessing {split_name} split ({len(image_list)} images)...")

#     for new_image_name in image_list:
#         # Calculate original image index
#         img_index = int(new_image_name.split('_')[1].split('.')[0])

#         # Original image name pattern (every 5th image starting from 0)
#         original_index = img_index * 5
#         old_image_name = f"train_{original_index:06d}.jpg"

#         source_path = os.path.join(source_images_dir, old_image_name)
#         target_path = os.path.join(target_dir, new_image_name)

#         if os.path.exists(source_path):
#             try:
#                 import shutil
#                 shutil.copy2(source_path, target_path)

#                 # Validate image can be opened
#                 with Image.open(target_path) as img:
#                     if img.size[0] > 0 and img.size[1] > 0:
#                         valid_images[split_name].append(new_image_name)
#                         copied_count += 1
#                     else:
#                         print(f"‚ö†Ô∏è Invalid image dimensions: {new_image_name}")

#             except Exception as e:
#                 print(f"‚ö†Ô∏è Failed to copy {old_image_name} -> {new_image_name}: {e}")
#         else:
#             print(f"‚ö†Ô∏è Source image not found: {source_path}")

#         # Show progress every 500 images
#         if len(valid_images[split_name]) % 500 == 0 and len(valid_images[split_name]) > 0:
#             print(f"  Copied {len(valid_images[split_name])} images...")

#     print(f"  ‚úÖ {split_name}: {len(valid_images[split_name])} valid images")

# print(f"\n‚úÖ Image organization complete!")
# print(f"üìä Successfully copied {copied_count} total images")
# print(f"üìä Final counts:")
# for split_name in ['train', 'val', 'test']:
#     print(f"  {split_name}: {len(valid_images[split_name])} images")

# print(f"\n‚úÖ Section 5 Fix Complete! Run Section 6 next.")

print("üîç DEBUGGING STEP 1: Basic System Check")
print("=" * 40)

import time
start_time = time.time()

# Check if we can even access the directories
try:
    target_files = os.listdir("data/images")
    print(f"‚úÖ Target directory accessible: {len(target_files)} files")
except Exception as e:
    print(f"‚ùå Target directory issue: {e}")

try:
    source_files = os.listdir("data/raw/Images")
    print(f"‚úÖ Source directory accessible: {len(source_files)} files")
except Exception as e:
    print(f"‚ùå Source directory issue: {e}")

elapsed = time.time() - start_time
print(f"‚è±Ô∏è Basic checks took: {elapsed:.2f} seconds")

# If this is fast, the issue is elsewhere
# If this is slow, we have a file system problem

print("üîç DEBUGGING STEP 2: Find Exact Failure Point")
print("=" * 40)

# Find what we actually have
copied_files = [f for f in os.listdir("data/images") if f.startswith("flickr8k_")]
print(f"üìä Flickr8k files copied: {len(copied_files)}")

# Get the image numbers we successfully copied
copied_numbers = []
for f in copied_files:
    try:
        num = int(f.split('_')[1].split('.')[0])
        copied_numbers.append(num)
    except:
        pass

if copied_numbers:
    copied_numbers.sort()
    max_copied = max(copied_numbers)
    print(f"üìä Highest number copied: {max_copied}")
    print(f"üìä Range: {min(copied_numbers)} to {max_copied}")

    # Check for gaps in sequence
    expected = set(range(min(copied_numbers), max_copied + 1))
    actual = set(copied_numbers)
    missing = expected - actual

    if missing:
        print(f"‚ö†Ô∏è Missing numbers: {sorted(list(missing))[:10]}...")  # Show first 10
    else:
        print("‚úÖ No gaps in sequence")

    # The next image to copy (where it failed)
    next_to_copy = max_copied + 1
    print(f"\nüéØ Next image to copy: flickr8k_{next_to_copy:06d}.jpg")

    # Check if this image should exist in our train set
    if next_to_copy < len(train_images):
        print(f"‚úÖ This image should be in train set")

        # Calculate source file
        source_idx = next_to_copy * 5
        source_file = f"train_{source_idx:06d}.jpg"
        source_path = f"data/raw/Images/{source_file}"

        print(f"üìÇ Looking for source: {source_file}")
        print(f"üìÇ Path exists: {os.path.exists(source_path)}")

        if os.path.exists(source_path):
            size = os.path.getsize(source_path)
            print(f"üìÇ File size: {size:,} bytes")

            # Try opening it
            try:
                from PIL import Image
                with Image.open(source_path) as img:
                    print(f"‚úÖ Image opens fine: {img.size} {img.mode}")
            except Exception as e:
                print(f"‚ùå Cannot open image: {e}")
        else:
            print(f"‚ùå Source file missing!")
    else:
        print(f"‚ö†Ô∏è Beyond train set - should be in val/test")

print("üîç DEBUGGING STEP 3: Check Image Mapping Logic")
print("=" * 40)

# Check what source images we actually have
source_files = os.listdir("data/raw/Images")
source_numbers = []

for f in source_files:
    if f.startswith("train_") and f.endswith(".jpg"):
        try:
            num = int(f.split('_')[1].split('.')[0])
            source_numbers.append(num)
        except:
            pass

source_numbers.sort()
print(f"üìä Source images range: {min(source_numbers)} to {max(source_numbers)}")
print(f"üìä Total source images: {len(source_numbers)}")

# Check if they're sequential every 5
expected_sequence = list(range(0, max(source_numbers) + 1, 5))
actual_set = set(source_numbers)
expected_set = set(expected_sequence)

missing_expected = expected_set - actual_set
print(f"üìä Missing from expected sequence: {len(missing_expected)}")
if missing_expected:
    print(f"   First few missing: {sorted(list(missing_expected))[:10]}")

# Check the pattern
print(f"\nüîç First 20 source images: {source_numbers[:20]}")
print(f"üîç Pattern check - every 5th: {source_numbers[::5][:10]}")

print("üîç DEBUGGING STEP 4: Check Failed Copies")
print("=" * 40)

# Let's manually check some of the "missing" numbers
missing_samples = [2, 3, 4, 5, 7, 8, 9]  # From our earlier output

for img_num in missing_samples:
    print(f"\nüîç Checking missing image {img_num}:")

    # Calculate source
    source_idx = img_num * 5
    source_file = f"train_{source_idx:06d}.jpg"
    source_path = f"data/raw/Images/{source_file}"

    # Calculate target
    target_file = f"flickr8k_{img_num:06d}.jpg"
    target_path = f"data/images/{target_file}"

    print(f"  Source: {source_file} (exists: {os.path.exists(source_path)})")
    print(f"  Target: {target_file} (exists: {os.path.exists(target_path)})")

    if os.path.exists(source_path) and not os.path.exists(target_path):
        # Try to copy this one manually
        try:
            import shutil
            shutil.copy2(source_path, target_path)
            print(f"  ‚úÖ Manual copy successful!")
        except Exception as e:
            print(f"  ‚ùå Manual copy failed: {e}")
            break  # Stop at first error
    elif os.path.exists(target_path):
        print(f"  ‚ÑπÔ∏è Target actually exists - counting error?")

# Quick recount
actual_copied = len([f for f in os.listdir("data/images") if f.startswith("flickr8k_")])
print(f"\nüìä Actual files after check: {actual_copied}")

print("üîß SECTION 5 FIX v2: ROBUST IMAGE COPYING")
print("=" * 50)

import shutil
import time
from PIL import Image

def robust_copy_images():
    """Copy images with proper error handling and progress"""

    # Count what we have so far
    existing_files = [f for f in os.listdir("data/images") if f.startswith("flickr8k_")]
    existing_numbers = set()

    for f in existing_files:
        try:
            num = int(f.split('_')[1].split('.')[0])
            existing_numbers.add(num)
        except:
            pass

    print(f"üìä Starting with {len(existing_numbers)} existing files")

    # Process each split
    for split_name, image_list in [('train', train_images), ('val', val_images), ('test', test_images)]:
        print(f"\nüìã Processing {split_name} split ({len(image_list)} images)...")

        successful = 0
        failed = 0
        skipped = 0

        for i, new_image_name in enumerate(image_list):
            # Extract image number
            img_num = int(new_image_name.split('_')[1].split('.')[0])

            # Skip if already exists
            if img_num in existing_numbers:
                skipped += 1
                continue

            # Calculate source path
            source_idx = img_num * 5
            source_file = f"train_{source_idx:06d}.jpg"
            source_path = f"data/raw/Images/{source_file}"
            target_path = f"data/images/{new_image_name}"

            # Copy with error handling
            try:
                # Add small delay to prevent overwhelming Google Drive
                if i % 50 == 0 and i > 0:
                    time.sleep(0.5)  # Brief pause every 50 files

                shutil.copy2(source_path, target_path)

                # Validate the copy
                with Image.open(target_path) as img:
                    if img.size[0] > 0 and img.size[1] > 0:
                        successful += 1
                        existing_numbers.add(img_num)
                    else:
                        failed += 1
                        os.remove(target_path)  # Remove invalid file

            except Exception as e:
                failed += 1
                print(f"  ‚ö†Ô∏è Failed to copy {new_image_name}: {e}")

                # If too many failures, stop and investigate
                if failed > 10:
                    print(f"  üõë Too many failures, stopping to investigate")
                    break

            # Progress updates
            if (successful + failed + skipped) % 500 == 0:
                print(f"    Progress: {successful} success, {failed} failed, {skipped} skipped")

        print(f"  ‚úÖ {split_name}: {successful} copied, {failed} failed, {skipped} skipped")

        # Stop if too many failures
        if failed > 10:
            break

    return existing_numbers

# Run the robust copy
final_copied = robust_copy_images()
print(f"\nüéâ Final result: {len(final_copied)} images ready")

print("üìÑ SECTION 6 FIX v2: CREATING JSONL FILES (CORRECTED)")
print("=" * 50)

# Rebuild valid_images from what we actually have
print("üîß Rebuilding valid_images from copied files...")

# Get all successfully copied images
copied_files = [f for f in os.listdir("data/images") if f.startswith("flickr8k_")]
copied_image_names = set(copied_files)

print(f"üìä Found {len(copied_image_names)} copied images")

# Rebuild valid_images by checking which images from each split actually exist
valid_images = {'train': [], 'val': [], 'test': []}

for split_name, image_list in [('train', train_images), ('val', val_images), ('test', test_images)]:
    for img_name in image_list:
        if img_name in copied_image_names:
            valid_images[split_name].append(img_name)

    print(f"üìä {split_name}: {len(valid_images[split_name])} valid images")

# Now create JSONL files with corrected valid_images
def create_jsonl_fixed(image_list, split_name, output_file):
    """Create JSONL file with proper format"""
    entries = []

    for img_name in image_list:
        if img_name not in captions_dict:
            print(f"‚ö†Ô∏è No captions found for {img_name}")
            continue

        # Create entry for each caption
        for i, caption in enumerate(captions_dict[img_name]):
            entry = {
                'image_path': f'data/images/{img_name}',
                'caption': caption,
                'image_id': img_name.split('.')[0],  # Remove .jpg extension
                'caption_id': f"{img_name.split('.')[0]}_{i}",
                'split': split_name
            }
            entries.append(entry)

    # Save JSONL
    with open(output_file, 'w', encoding='utf-8') as f:
        for entry in entries:
            f.write(json.dumps(entry) + '\n')

    print(f"  ‚úÖ {split_name}: {len(entries)} entries ‚Üí {output_file}")
    return entries

# Create JSONL files for each split
print("\nüìù Creating JSONL files...")

train_data = create_jsonl_fixed(valid_images['train'], 'train', 'data/train.jsonl')
val_data = create_jsonl_fixed(valid_images['val'], 'val', 'data/val.jsonl')
test_data = create_jsonl_fixed(valid_images['test'], 'test', 'data/test.jsonl')

print(f"\nüìä JSONL Files Created:")
print(f"  train.jsonl: {len(train_data)} entries")
print(f"  val.jsonl: {len(val_data)} entries")
print(f"  test.jsonl: {len(test_data)} entries")

# Verify average captions per image
print(f"\nüìä Verification - Average captions per image:")
for split_name, image_list in [('train', valid_images['train']), ('val', valid_images['val']), ('test', valid_images['test'])]:
    if image_list:
        total_captions = sum(len(captions_dict[img]) for img in image_list)
        avg_captions = total_captions / len(image_list)
        print(f"  {split_name}: {avg_captions:.1f} captions/image")

print(f"\n‚úÖ Section 6 Fix v2 Complete! Run Section 7 next.")

# ================================================================
# SECTION 7 FIX: FINAL VALIDATION & DOCUMENTATION
# ================================================================

print("üß™ SECTION 7 FIX: FINAL VALIDATION & DOCUMENTATION")
print("=" * 50)

# ================================================================
# FINAL VALIDATION
# ================================================================

print("üîç Final Validation:")

# Check all files exist
required_files = ['data/train.jsonl', 'data/val.jsonl', 'data/test.jsonl']
for file_path in required_files:
    if os.path.exists(file_path):
        size_mb = os.path.getsize(file_path) / (1024 * 1024)
        print(f"‚úÖ {file_path} ({size_mb:.2f} MB)")
    else:
        print(f"‚ùå Missing: {file_path}")

# Test data loading
print(f"\nüß™ Testing data loading:")
try:
    # Test JSONL format
    with open('data/train.jsonl', 'r') as f:
        sample_entry = json.loads(f.readline())

    print("‚úÖ JSONL format valid")
    print(f"üìã Sample entry keys: {list(sample_entry.keys())}")
    print(f"üìã Sample entry:")
    for key, value in sample_entry.items():
        if key == 'caption':
            print(f"  {key}: {value[:50]}...")  # Truncate long captions
        else:
            print(f"  {key}: {value}")

    # Test image loading
    sample_image_path = sample_entry['image_path']
    if os.path.exists(sample_image_path):
        with Image.open(sample_image_path) as img:
            print(f"‚úÖ Sample image loads: {img.size} {img.mode}")
    else:
        print(f"‚ùå Sample image missing: {sample_image_path}")

except Exception as e:
    print(f"‚ùå Data loading test failed: {e}")

# ================================================================
# CREATE DOCUMENTATION
# ================================================================

print(f"\nüìö Creating documentation...")

# Calculate file checksums for reproducibility
def calculate_checksum(file_path):
    """Calculate MD5 checksum of file"""
    import hashlib
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

# Create README
readme_content = f"""# Flickr8k Dataset - CLIP Project (Fixed)

## Dataset Information
- **Source**: HuggingFace ariG23498/flickr8k (processed correctly)
- **Total Unique Images**: {len(unique_images)}
- **Total Captions**: {len(train_data) + len(val_data) + len(test_data)}

## Processing Applied
- **Fixed grouping**: Every 5 captions grouped to 1 unique image
- **Proper splits**: Split by unique images (not by captions)
- **Image renaming**: train_000000.jpg ‚Üí flickr8k_000000.jpg pattern

## Splits
- **Train**: {len(valid_images['train'])} images, {len(train_data)} captions
- **Validation**: {len(valid_images['val'])} images, {len(val_data)} captions
- **Test**: {len(valid_images['test'])} images, {len(test_data)} captions

## File Checksums (for reproducibility)
- `train.jsonl`: {calculate_checksum('data/train.jsonl')}
- `val.jsonl`: {calculate_checksum('data/val.jsonl')}
- `test.jsonl`: {calculate_checksum('data/test.jsonl')}

## Data Format
Each JSONL file contains entries with:
- `image_path`: Relative path to image file
- `caption`: Preprocessed caption text (lowercase, normalized)
- `image_id`: Unique image identifier
- `caption_id`: Unique caption identifier
- `split`: Dataset split name

## Preprocessing Applied
- Captions converted to lowercase
- Whitespace normalized
- UTF-8 encoding ensured
- Images validated for corruption
- Images renamed for clarity (flickr8k_XXXXXX.jpg)

## Usage
```python
import json

# Load training data
with open('data/train.jsonl', 'r') as f:
    train_data = [json.loads(line) for line in f]
```

Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

with open('data/README.md', 'w', encoding='utf-8') as f:
    f.write(readme_content)

print("‚úÖ Dataset documentation created: data/README.md")

# ================================================================
# FINAL SUMMARY
# ================================================================

print(f"\n" + "="*60)
print("üéâ DATASET PREPARATION COMPLETE!")
print("="*60)

print(f"üìä Final Dataset Statistics:")
print(f"  Unique Images: {len(unique_images)}")
print(f"  Train: {len(valid_images['train'])} images, {len(train_data)} captions")
print(f"  Val:   {len(valid_images['val'])} images, {len(val_data)} captions")
print(f"  Test:  {len(valid_images['test'])} images, {len(test_data)} captions")

avg_captions = (len(train_data) + len(val_data) + len(test_data)) / len(unique_images)
print(f"  Average captions per image: {avg_captions:.1f}")

print(f"\nüìÅ Files Created:")
print(f"  ‚Ä¢ data/train.jsonl ({len(train_data)} entries)")
print(f"  ‚Ä¢ data/val.jsonl ({len(val_data)} entries)")
print(f"  ‚Ä¢ data/test.jsonl ({len(test_data)} entries)")
print(f"  ‚Ä¢ data/images/ ({sum(len(v) for v in valid_images.values())} images)")
print(f"  ‚Ä¢ data/README.md (documentation)")

print(f"\nüöÄ Ready for Phase 2: Zero-shot Baseline!")
print("üí° Next: Create zero-shot encoding notebook")

# Save project state for next phase
project_state = {
    'phase_completed': 'data_preparation_fixed',
    'dataset': 'flickr8k_grouped_corrected',
    'total_unique_images': len(unique_images),
    'total_captions': len(train_data) + len(val_data) + len(test_data),
    'splits': {
        'train': {'images': len(valid_images['train']), 'captions': len(train_data)},
        'val': {'images': len(valid_images['val']), 'captions': len(val_data)},
        'test': {'images': len(valid_images['test']), 'captions': len(test_data)}
    },
    'project_root': project_root,
    'next_phase': 'zero_shot_baseline'
}

with open('artifacts/project_state.json', 'w') as f:
    json.dump(project_state, f, indent=2)

print("üíæ Project state saved to artifacts/project_state.json")
print(f"\n‚úÖ Section 7 Fix Complete! Data preparation finished!")
